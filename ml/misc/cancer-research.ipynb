{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3/dist-packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import lzma\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = !pwd\n",
    "sys.path.append(path[0])\n",
    "sys.path.append(os.path.abspath(path[0] + '/../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data_dir = '/home/noskill/projects/cancer.old/data'\n",
    "dataset_dict = load_merged_dataset(cancer_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmc = dataset_dict['bmc']\n",
    "bmc = bmc.sort_values(by='patient_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load detailed treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = dataset_dict['treatment'].sort_values(by='patient_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load genes expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_features = dataset_dict['genes_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_features = genes_features.sort_values(by='patient_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# columns to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam50col = genes_features.columns[genes_features.columns.isin(pam50).nonzero()[0]].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_treatment_columns = ['radio', 'surgery', 'chemo', 'hormone']\n",
    "label_columns = ['pCR', 'RFS', 'DFS', 'posOutcome']\n",
    "label_columns = ['posOutcome']\n",
    "genes_columns = genes_features.columns.to_list()[1:]\n",
    "feature_columns =  xgboost_top_100 # genes_columns + treatment_columns #  # label_columns +  # pam50col #  +   + aggregated_treatment_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merged genes expression + averaged treatment + detailed treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = dataset_dict['merged']\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(list)\n",
    "model = CatBoostClassifier(iterations=3600,\n",
    "                           depth=7,\n",
    "                           use_best_model=True,\n",
    "                           learning_rate=0.005,\n",
    "                           loss_function='Logloss',\n",
    "                           model_size_reg=20,\n",
    "                           verbose=True,\n",
    "                           scale_pos_weight=0.605,\n",
    "                           l2_leaf_reg=20,\n",
    "                           od_type='Iter', od_wait=200)\n",
    "model = CatBoostClassifier(verbose=True)\n",
    "train_data, train_labels, val_data, val_labels = random_split(merged,\n",
    "                                                              feature_columns, \n",
    "                                                              label_columns)\n",
    "catboost_pool = Pool(train_data, \n",
    "                    train_labels)\n",
    "\n",
    "test_data = Pool(val_data,\n",
    "                 val_labels) \n",
    "# train the model\n",
    "clf = model.fit(train_data, train_labels, \n",
    "          eval_set=test_data,\n",
    "          save_snapshot=False, snapshot_file='vasya')\n",
    "y_pred = clf.predict(val_data)\n",
    "x_pred = clf.predict(train_data)\n",
    "compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "res = defaultdict(list)\n",
    "\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    model = xgb.XGBClassifier()\n",
    "\n",
    "    train_data, train_labels, val_data, val_labels = random_split(merged,\n",
    "                                                                  feature_columns, \n",
    "                                                                  label_columns)\n",
    "\n",
    "    # train the model\n",
    "    clf = model.fit(train_data, train_labels,\n",
    "                    eval_set=[(train_data, train_labels), (val_data, val_labels)], \n",
    "                    early_stopping_rounds=50, verbose=False)\n",
    "    y_pred = clf.predict(val_data)\n",
    "    x_pred = clf.predict(train_data)\n",
    "    compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in res:\n",
    "    ave = numpy.asarray(res[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_sorted = sorted([(y, x) for (x,y) in weights.items()], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[feature_columns[int(num[1:])] for (_, num) in weights_sorted[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (w, num) in weights_sorted[:100]:\n",
    "    print(feature_columns[int(num[1:])], w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "svm_total = defaultdict(list)\n",
    "for i in range(5):\n",
    "    print('iteration {0}'.format(i))\n",
    "    model = svm.SVC(C=1, kernel='rbf', class_weight={1: 0.5})\n",
    "    train_data, train_labels, val_data, val_labels = random_split(merged,\n",
    "                                                                  feature_columns, \n",
    "                                                                  label_columns)\n",
    "    # train the model\n",
    "    clf = model.fit(numpy.nan_to_num(train_data), numpy.nan_to_num(train_labels))\n",
    "    y_pred = clf.predict(numpy.nan_to_num(val_data))\n",
    "    x_pred = clf.predict(numpy.nan_to_num(train_data))\n",
    "    compute_metrics(svm_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in svm_total:\n",
    "    ave = numpy.asarray(svm_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - single study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "svm_total = defaultdict(list)\n",
    "for study in set(bmc.study):\n",
    "    print('\\n' * 2 + str(study))\n",
    "    for i in range(20):\n",
    "        train_data, train_labels, val_data, val_labels = random_split(merged,\n",
    "                                                                  feature_columns, \n",
    "                                                                  label_columns, ratio=0.1, study_name=study)\n",
    "        C = 1\n",
    "        model = svm.SVC(C=C, kernel='rbf', class_weight={1: (1 - numpy.mean(train_labels))  / numpy.mean(train_labels)})\n",
    "        # train the model\n",
    "        clf = model.fit(numpy.nan_to_num(train_data), numpy.nan_to_num(train_labels))\n",
    "        y_pred = clf.predict(numpy.nan_to_num(val_data))\n",
    "        # print(y_pred)\n",
    "        x_pred = clf.predict(numpy.nan_to_num(train_data))\n",
    "        compute_metrics(svm_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in svm_total:\n",
    "    ave = numpy.asarray(svm_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nearest neigbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_data, validation_data, train_labels):\n",
    "    tmp = []\n",
    "    for i in range(len(validation_data)):\n",
    "        diff = train_data - validation_data[i]\n",
    "        idx = numpy.argmin(numpy.sqrt(numpy.sum(diff ** 2, axis=1)))\n",
    "        tmp.append(idx)\n",
    "    return train_labels[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_total = defaultdict(list)\n",
    "for i in range(10):\n",
    "    train_data, train_labels, val_data, val_labels = random_split(merged,\n",
    "                                                                  feature_columns, \n",
    "                                                                  label_columns)\n",
    "    y_pred = predict(numpy.nan_to_num(train_data), numpy.nan_to_num(val_data), train_labels)\n",
    "    x_pred = predict(numpy.nan_to_num(train_data), numpy.nan_to_num(train_data), train_labels)\n",
    "    compute_metrics(nearest_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "\n",
    "for key in nearest_total:\n",
    "    ave = numpy.asarray(nearest_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_total = defaultdict(list)\n",
    "for i in range(10):\n",
    "    gnb = GaussianNB()\n",
    "    train_data, train_labels, val_data, val_labels = random_split(merged,\n",
    "                                                                  feature_columns, \n",
    "                                                                  label_columns)\n",
    "    print(val_labels.sum() / len(val_labels))\n",
    "    model = gnb.fit(numpy.nan_to_num(train_data, nan=-1), numpy.nan_to_num(train_labels))\n",
    "    y_pred = model.predict(numpy.nan_to_num(val_data, nan=-1))\n",
    "    x_pred = model.predict(numpy.nan_to_num(train_data))\n",
    "    compute_metrics(nearest_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "\n",
    "for key in nearest_total:\n",
    "    ave = numpy.asarray(nearest_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data = binarize_dataset(merged, genes_columns, feature_columns, to_letters=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data.taxaneGeneral.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin_data.drop('patient_ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test binarization by xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "res = defaultdict(list)\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = xgb.XGBClassifier()\n",
    "\n",
    "    train_data, train_labels, val_data, val_labels = random_split(bin_data,\n",
    "                                                                  feature_columns, \n",
    "                                                                  label_columns)\n",
    "\n",
    "    # train the model\n",
    "    clf = model.fit(train_data, train_labels,\n",
    "                    eval_set=[(train_data, train_labels), (val_data, val_labels)], \n",
    "                    early_stopping_rounds=50, verbose=False)\n",
    "    print(val_labels.sum() / len(val_labels))\n",
    "    y_pred = clf.predict(val_data)\n",
    "    x_pred = clf.predict(train_data)\n",
    "    compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in res:\n",
    "    ave = numpy.asarray(res[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test leave one study out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data.study.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util.util import study_mapping\n",
    "res = defaultdict(list)\n",
    "for study_name, study_id in study_mapping.items():\n",
    "    train_data, train_labels, val_data, val_labels = next(split_by_study(bin_data,\n",
    "                                                              feature_columns, \n",
    "                                                              label_columns,\n",
    "                                                              study=study_id,\n",
    "                                                              to_numpy=True))\n",
    "    print(study_name)\n",
    "    model = xgb.XGBClassifier()\n",
    "    # train the model\n",
    "    clf = model.fit(train_data, train_labels,\n",
    "                   eval_set=[(train_data, train_labels), (val_data, val_labels)], \n",
    "                   early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "    print(val_data.shape)\n",
    "    print(val_labels.sum() / len(val_labels))\n",
    "    y_pred = clf.predict(val_data)\n",
    "    x_pred = clf.predict(train_data)\n",
    "    compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in res:\n",
    "   ave = numpy.asarray(res[key]).mean(axis=0)\n",
    "   print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['confusion'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_moses_features = ['posOutcome'] + feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels = random_split(bin_data,\n",
    "                                                              subset_moses_features, \n",
    "                                                              label_columns,\n",
    "                                                              balance_by_study=True,\n",
    "                                                              to_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subset_moses_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('/tmp/cancer_bin_100_train_balance_by_study.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.to_csv('/tmp/cancer_bin_100_val_balance.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leave one study out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util.util import study_mapping\n",
    "for study_name, study_id in study_mapping.items():\n",
    "    train_data, train_labels, val_data, val_labels = next(split_by_study(bin_data,\n",
    "                                                              subset_moses_features, \n",
    "                                                              label_columns,\n",
    "                                                              study=study_id,\n",
    "                                                              to_numpy=False))\n",
    "    print(study_name)\n",
    "    print(train_data.shape)\n",
    "    print(val_data.shape)\n",
    "    train_data.to_csv('/tmp/cancer_bin_100_train_leave_{0}.csv'.format(study_name),\n",
    "                      header=True, index=False)\n",
    "    val_data.to_csv('/tmp/cancer_bin_100_val_leave_{0}.csv'.format(study_name),\n",
    "                    header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_data, train_labels, val_data, val_labels = next(split_by_study(bin_data,\n",
    "                                                              subset_moses_features, \n",
    "                                                              label_columns,\n",
    "                                                              study=study_id,\n",
    "                                                              to_numpy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged.study == 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data.study.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencog.pyasmoses import moses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels, expected = random_split(ratio=0.1, to_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(-1)\n",
    "train_data.to_csv('/tmp/input_data.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_data.surgery_type.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = numpy.concatenate([train_labels[..., numpy.newaxis], train_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = moses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = \"--log-file log1.txt.log --hc-fraction-of-nn 0.01 -j5 --balance 1 -m 100000 --result-count 100 --reduct-knob-building-effort=2 --hc-widen-search=1 --enable-fs=1 --fs-algo=smd --fs-target-size=1000 --hc-crossover-min-neighbors=5000 --fs-focus=all --fs-seed=init  --hc-max-nn-evals=10000 --hc-crossover-pop-size=1000 -l debug --noise 0.2 -q 0.05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mos.run(input=numpy.nan_to_num(input_data), python=True, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = moses()\n",
    "input_data = [[0, 0, 0],\n",
    "              [0.2, 0.2, 0.4],\n",
    "              [1, 1, 2],\n",
    "              [1, 0, 1],\n",
    "              [2., 1, 3]]\n",
    "output = mos.run(input=input_data, python=True, args='-m 1000000 --max-time=60 --balance=1')\n",
    "print (output[0].score) # Prints: 0\n",
    "model = output[0].eval\n",
    "print(model([0, 1]))  # Returns: True\n",
    "print(model([1, 1]))  # Returns: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moses_args = []\n",
    "# target column\n",
    "moses_args.append('--problem_type=it')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
